{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plankton VGG mashup\n",
    "This notebook contains a mashup of VGG12 and the Kaggle National Data Science Bowl plankton competition. The data can be obtained at Kaggle on https://www.kaggle.com/c/datasciencebowl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "* Guestimate validation set size in accordance with Kaggle\n",
    "* Reshape last three dense layers: done\n",
    "* Data sample and validation : done\n",
    "* Change means: done\n",
    "* Add batchnorm: done, verify some\n",
    "* Add dropout: done, verify some\n",
    "* Check grayscale imaging: done\n",
    "* Verify number of parameters: done\n",
    "* Create submission\n",
    "* Save model: done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is enabled with initial size: 25.0% of memory, cuDNN 5105)\n",
      "/home/sanne/virtualenvs/nn/local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import random\n",
    "import math\n",
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import plots\n",
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data_dir = \"/home/sanne/Data/plankton\"\n",
    "train_dir = data_dir + '/train'\n",
    "sample_dir = data_dir + '/sample'\n",
    "valid_dir = data_dir + '/valid'\n",
    "\n",
    "n_train = 30336\n",
    "n_validation = int(0.2 * n_train)\n",
    "n_sample = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom PIL import Image\\n\\ndef get_mean(tf):\\n    im = Image.open(train_dir+train_files[0])\\n    im = im.convert(\"RGB\")\\n    im = im.resize((224,224))\\n    data = np.array(im)\\n    #print(data.shape)\\n    return data.mean()\\n    \\nmeans = []\\nfor train_file in get_files(train_dir):\\n    means.append(get_mean(train_file))\\n    \\nprint(np.mean(means))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from PIL import Image\n",
    "\n",
    "def get_mean(tf):\n",
    "    im = Image.open(train_dir+train_files[0])\n",
    "    im = im.convert(\"RGB\")\n",
    "    im = im.resize((224,224))\n",
    "    data = np.array(im)\n",
    "    #print(data.shape)\n",
    "    return data.mean()\n",
    "    \n",
    "means = []\n",
    "for train_file in get_files(train_dir):\n",
    "    means.append(get_mean(train_file))\n",
    "    \n",
    "print(np.mean(means))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_files(d):\n",
    "    return [f[len(d):] for f in glob.glob(d + '/*/*')]    \n",
    "\n",
    "def get_subdirs(d):\n",
    "    return [f[len(d):] for f in glob.glob(d + '/*')]    \n",
    "    \n",
    "def copy_subdirs(frm, to):\n",
    "    subdirs = [f[len(frm):] for f in glob.glob(frm + '/*')]\n",
    "    for s in subdirs:\n",
    "        os.system(\"mkdir -p %s\" % (to + s))\n",
    "        \n",
    "def create_sample(n):\n",
    "    # Destroy and create new samples\n",
    "    os.system(\"rm -rf {}\".format(sample_dir))\n",
    "    \n",
    "    dirs = ['/valid', '/train', '/test']\n",
    "    \n",
    "    for d in dirs:\n",
    "        os.system(\"mkdir -p %s\" % (sample_dir + d))\n",
    "\n",
    "    # Create all class in valid and train sample\n",
    "    for d in dirs[:-1]:\n",
    "        copy_subdirs(train_dir, sample_dir+d)\n",
    "\n",
    "    os.system(\"mkdir -p %s\" % (sample_dir + '/test/unknown'))\n",
    "\n",
    "    for sample in random.sample(get_files(train_dir), n):\n",
    "        target_dir = random.sample(dirs,1)[0]\n",
    "        if not target_dir == '/test':\n",
    "            os.system(\"cp %s %s\" % \\\n",
    "                             (train_dir + sample, sample_dir + target_dir + sample))\n",
    "        else:\n",
    "            os.system(\"cp %s %s\" % \\\n",
    "                             (train_dir + sample, sample_dir + target_dir + '/unknown/' + sample.split('/')[-1]))\n",
    "\n",
    "def create_validation(n, clean=False):\n",
    "    # Place files back\n",
    "    files = get_files(valid_dir)\n",
    "    for f in get_files(valid_dir):\n",
    "        os.system(\"mv %s %s\" % \\\n",
    "                         (valid_dir + f, train_dir + f))\n",
    "        \n",
    "    if clean:\n",
    "        return\n",
    "    \n",
    "    # Destroy and create new validation set\n",
    "    os.system(\"rm -rf {}\".format(valid_dir))\n",
    "    \n",
    "    # Create all class in valid and train sample\n",
    "    copy_subdirs(train_dir, valid_dir)\n",
    "    \n",
    "    for sample in random.sample(get_files(train_dir), n):\n",
    "        os.system(\"mkdir -p %s\" % \\\n",
    "                         (os.path.dirname(valid_dir + sample)))\n",
    "        os.system(\"mv %s %s\" % \\\n",
    "                         (train_dir + sample, valid_dir + sample))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncreate_sample(n_sample)\\ncreate_validation(n_validation)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "create_sample(n_sample)\n",
    "create_validation(n_validation)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 24269 in 121\n",
      "Number of validation examples: 6067 in 121\n",
      "Total examples: 30336/30336\n",
      "Number of train samples: 46 in 121\n",
      "Number of valid samples: 54 in 121\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of training examples: {} in {}\".format(len(get_files(train_dir)), \\\n",
    "                                                     len(get_subdirs(train_dir))))\n",
    "print (\"Number of validation examples: {} in {}\".format(len(get_files(valid_dir)), \\\n",
    "                                                       len(get_subdirs(valid_dir))))\n",
    "\n",
    "print (\"Total examples: {}/{}\".format(len(get_files(valid_dir))+len(get_files(train_dir)), 30336))\n",
    "\n",
    "print (\"Number of train samples: {} in {}\".format(len(get_files(sample_dir+'/train')), \\\n",
    "                                           len(get_subdirs(sample_dir+'/train'))))\n",
    "print (\"Number of valid samples: {} in {}\".format(len(get_files(sample_dir+'/valid')), \\\n",
    "                                           len(get_subdirs(sample_dir+'/valid'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, RMSprop\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FILES_PATH = 'http://www.platform.ai/models/'; CLASS_FILE='imagenet_class_index.json'\n",
    "# Keras' get_file() is a handy function that downloads files, and caches them for re-use later\n",
    "fpath = get_file(CLASS_FILE, FILES_PATH+CLASS_FILE, cache_subdir='models')\n",
    "with open(fpath) as f: class_dict = json.load(f)\n",
    "# Convert dictionary with string indexes into an array\n",
    "classes = [class_dict[str(i)][1] for i in range(len(class_dict))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "def ConvBlock(layers, model, filters, add=False):\n",
    "    for i in range(layers): \n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "        if add: model.add(BatchNormalization(axis=1))\n",
    "        if add: model.add(Dropout(0.5)) # verify\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    if add: model.add(BatchNormalization(axis=1)) # verify\n",
    "    if add: model.add(Dropout(0.5)) # verify\n",
    "    \n",
    "def FCBlock(model, add=False):\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    # BatchNorm should be applied before Dropout\n",
    "    #if add: model.add(BatchNormalization())\n",
    "    if add: model.add(Dropout(0.10))\n",
    "\n",
    "# Mean of each channel as provided by VGG researchers\n",
    "vgg_mean = np.array([242.96,242.96,242.96]).reshape((3,1,1))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean     # subtract mean\n",
    "    #return x[:, ::-1]    # reverse axis bgr->rgb\n",
    "    return x\n",
    "\n",
    "def VGG_16():\n",
    "    model = Sequential()\n",
    "    # samples x channels x width x height\n",
    "    # model.add(BatchNormalization(axis=1, input_shape=(3,176,176)))\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3,224,224), output_shape=(3,224,224)))\n",
    "\n",
    "    ConvBlock(2, model, 64)\n",
    "    ConvBlock(2, model, 128)\n",
    "    ConvBlock(3, model, 256)\n",
    "    ConvBlock(3, model, 512)\n",
    "    ConvBlock(3, model, 512)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    FCBlock(model)\n",
    "    FCBlock(model)\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, \n",
    "                batch_size=batch_size, class_mode='categorical'):\n",
    "    return gen.flow_from_directory(path+dirname, target_size=(224,224), \n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_plankton():\n",
    "\n",
    "    model = Sequential()\n",
    "    # samples x channels x width x height\n",
    "    # model.add(BatchNormalization(axis=1, input_shape=(3,176,176)))\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3,224,224), output_shape=(3,224,224)))\n",
    "\n",
    "    ConvBlock(2, model, 64, add=True)\n",
    "    ConvBlock(2, model, 128, add=True)\n",
    "    ConvBlock(3, model, 256, add=True)\n",
    "    ConvBlock(3, model, 512, add=True)\n",
    "    ConvBlock(3, model, 512, add=True)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #model.load_weights('conv_layers.h5')\n",
    "    \n",
    "    FCBlock(model, add=True)\n",
    "    FCBlock(model, add=True)\n",
    "    model.add(Dense(121, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def tune(model):   \n",
    "    for i in range(3): model.pop()\n",
    "    FCBlock(model)\n",
    "    FCBlock(model)\n",
    "    model.add(Dense(121, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def VGG_16():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3,224,224), output_shape=(3,224,224)))\n",
    "\n",
    "    ConvBlock(2, model, 64)\n",
    "    ConvBlock(2, model, 128)\n",
    "    ConvBlock(3, model, 256)\n",
    "    ConvBlock(3, model, 512)\n",
    "    ConvBlock(3, model, 512)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    FCBlock(model)\n",
    "    FCBlock(model)\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "fpath = get_file('vgg16.h5', FILES_PATH+'vgg16.h5', cache_subdir='models')\n",
    "model = VGG_16()\n",
    "model.load_weights(fpath)\n",
    "for i in range(3): model.pop()\n",
    "for layer in model.layers: layer.trainable=False\n",
    "FCBlock(model, True)\n",
    "FCBlock(model, True)\n",
    "model.add(Dense(121, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "color_mode=\"grayscale\"\n",
    "lr = 0.001\n",
    "nb_epoch = 15\n",
    "path = data_dir + \"/\"\n",
    "#path = data_dir + \"/sample/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24269 images belonging to 121 classes.\n",
      "Found 6067 images belonging to 121 classes.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  1792        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  36928       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 73856       zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 147584      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   295168      zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   1180160     zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   2359808     zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 121)           495737      dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 134,756,281\n",
      "Trainable params: 120,041,593\n",
      "Non-trainable params: 14,714,688\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/15\n",
      "24269/24269 [==============================] - 1029s - loss: 15.0519 - acc: 0.0658 - val_loss: 15.1086 - val_acc: 0.0626\n",
      "Epoch 2/15\n",
      "24269/24269 [==============================] - 1028s - loss: 15.0561 - acc: 0.0659 - val_loss: 15.1086 - val_acc: 0.0626\n",
      "Epoch 3/15\n",
      "24269/24269 [==============================] - 1027s - loss: 15.0561 - acc: 0.0659 - val_loss: 15.1086 - val_acc: 0.0626\n",
      "Epoch 4/15\n",
      "24269/24269 [==============================] - 1027s - loss: 15.0561 - acc: 0.0659 - val_loss: 15.1086 - val_acc: 0.0626\n",
      "Epoch 5/15\n",
      "24269/24269 [==============================] - 1028s - loss: 15.0561 - acc: 0.0659 - val_loss: 15.1086 - val_acc: 0.0626\n",
      "Epoch 6/15\n",
      "24269/24269 [==============================] - 1028s - loss: 15.0561 - acc: 0.0659 - val_loss: 15.1086 - val_acc: 0.0626\n",
      "Epoch 7/15\n",
      "24269/24269 [==============================] - 1028s - loss: 15.0561 - acc: 0.0659 - val_loss: 15.1086 - val_acc: 0.0626\n",
      "Epoch 8/15\n",
      "24269/24269 [==============================] - 1027s - loss: 15.0561 - acc: 0.0659 - val_loss: 15.1086 - val_acc: 0.0626\n",
      "Epoch 9/15\n",
      "24269/24269 [==============================] - 1027s - loss: 15.0561 - acc: 0.0659 - val_loss: 15.1086 - val_acc: 0.0626\n",
      "Epoch 10/15\n",
      "24269/24269 [==============================] - 1027s - loss: 15.0561 - acc: 0.0659 - val_loss: 15.1086 - val_acc: 0.0626\n",
      "Epoch 11/15\n",
      "24269/24269 [==============================] - 1028s - loss: 15.2481 - acc: 0.0540 - val_loss: 15.9932 - val_acc: 0.0077\n",
      "Epoch 12/15\n",
      "24269/24269 [==============================] - 1027s - loss: 15.9673 - acc: 0.0094 - val_loss: 15.9932 - val_acc: 0.0077\n",
      "Epoch 13/15\n",
      "24269/24269 [==============================] - 1027s - loss: 15.9673 - acc: 0.0094 - val_loss: 15.9932 - val_acc: 0.0077\n",
      "Epoch 14/15\n",
      "24269/24269 [==============================] - 1028s - loss: 15.9673 - acc: 0.0094 - val_loss: 15.9932 - val_acc: 0.0077\n",
      "Epoch 15/15\n",
      "24269/24269 [==============================] - 1027s - loss: 15.9673 - acc: 0.0094 - val_loss: 15.9932 - val_acc: 0.0077\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation\n",
    "#gen = image.ImageDataGenerator(rotation_range=360, width_shift_range=0.1, shear_range = 0.1, \\\n",
    "#                               height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)\n",
    "gen = image.ImageDataGenerator(rotation_range=45, width_shift_range=0.1, shear_range = 0.1, \\\n",
    "                               height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "# Get the batch driver\n",
    "batches = get_batches('train', batch_size=batch_size)\n",
    "val_batches = get_batches('valid', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# Create, compile and fit\n",
    "#model = create_plankton()\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(lr=lr),\n",
    "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=nb_epoch,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model.save_weights('plankton.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting imagenet predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pred_batch(model, imgs):\n",
    "    preds = model.predict_generator(test_batches, test_batches.nb_sample)\n",
    "    idxs = np.argmax(preds, axis=1)\n",
    "\n",
    "    print('Shape: {}'.format(preds.shape))\n",
    "    print('First 5 classes: {}'.format(classes[:5]))\n",
    "    print('First 5 probabilities: {}\\n'.format(preds[0, :5]))\n",
    "    print('Predictions prob/class: ')\n",
    "    \n",
    "    for i in range(len(idxs)):\n",
    "        idx = idxs[i]\n",
    "        print ('  {:.4f}/{}'.format(preds[i, idx], classes[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59 images belonging to 1 classes.\n",
      "Shape: (59, 121)\n",
      "First 5 classes: [u'tench', u'goldfish', u'great_white_shark', u'tiger_shark', u'hammerhead']\n",
      "First 5 probabilities: [  1.1670e-12   9.3122e-13   9.4961e-08   1.7425e-09   1.6834e-06]\n",
      "\n",
      "Predictions prob/class: \n",
      "  0.7026/quail\n",
      "  0.8684/flatworm\n",
      "  0.9999/flatworm\n",
      "  0.9999/brambling\n",
      "  0.8062/axolotl\n",
      "  1.0000/black_and_gold_garden_spider\n",
      "  0.9968/spotted_salamander\n",
      "  0.4372/axolotl\n",
      "  0.7142/African_chameleon\n",
      "  0.3819/loggerhead\n",
      "  0.8120/axolotl\n",
      "  0.2671/axolotl\n",
      "  1.0000/brambling\n",
      "  0.9983/black_and_gold_garden_spider\n",
      "  0.9632/black_and_gold_garden_spider\n",
      "  0.9961/goose\n",
      "  0.7372/African_chameleon\n",
      "  0.5078/brambling\n",
      "  1.0000/brambling\n",
      "  0.5732/brambling\n",
      "  0.9907/black_and_gold_garden_spider\n",
      "  0.8119/African_chameleon\n",
      "  0.6135/spotted_salamander\n",
      "  1.0000/spotted_salamander\n",
      "  0.9937/sea_slug\n",
      "  0.9955/peacock\n",
      "  0.8988/African_chameleon\n",
      "  0.9042/African_chameleon\n",
      "  1.0000/brambling\n",
      "  0.4219/axolotl\n",
      "  0.5819/brambling\n",
      "  1.0000/brambling\n",
      "  0.7658/goose\n",
      "  0.7163/loggerhead\n",
      "  1.0000/black_and_gold_garden_spider\n",
      "  0.4389/chickadee\n",
      "  0.4900/loggerhead\n",
      "  0.9724/axolotl\n",
      "  0.9075/spotted_salamander\n",
      "  0.3581/African_chameleon\n",
      "  0.8935/goose\n",
      "  0.5842/goose\n",
      "  0.6139/axolotl\n",
      "  0.9995/brambling\n",
      "  0.9998/brambling\n",
      "  0.9987/black_and_gold_garden_spider\n",
      "  0.9958/axolotl\n",
      "  1.0000/black_and_gold_garden_spider\n",
      "  0.8750/spotted_salamander\n",
      "  0.9372/axolotl\n",
      "  1.0000/black_and_gold_garden_spider\n",
      "  0.9999/brambling\n",
      "  0.6667/brambling\n",
      "  1.0000/black_and_gold_garden_spider\n",
      "  1.0000/brambling\n",
      "  0.8049/peacock\n",
      "  1.0000/brambling\n",
      "  0.4663/spotted_salamander\n",
      "  0.6750/axolotl\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches('/test', shuffle=False, batch_size=batch_size, class_mode=None)\n",
    "model = tune(create_vgg())\n",
    "model.load_weights(\"plankton.h5\")\n",
    "pred_batch(model, test_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2]\n",
    "b = [3, 4]\n",
    "print(a.extend(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
